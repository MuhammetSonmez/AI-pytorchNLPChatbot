# -*- coding: utf-8 -*-
"""nlpChatbot.ipynb

Automatically generated by Colaboratory.

"""

import nltk
from nltk.stem.porter import PorterStemmer
import json
import numpy as np

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

import random

class Internal_dataset:
  def __init__(self) -> None:
    self.data = """
      {
        "intents": [
          {
            "tag": "greeting",
            "patterns": [
              "Hi",
              "Hey",
              "How are you",
              "Is anyone there?",
              "Hello",
              "Good day"
            ],
            "responses": [
              "Hey :-)",
              "Hello, thanks for visiting",
              "Hi there, what can I do for you?",
              "Hi there, how can I help?"
            ]
          },
          {
            "tag": "goodbye",
            "patterns": ["Bye", "See you later", "Goodbye"],
            "responses": [
              "See you later, thanks for visiting",
              "Have a nice day",
              "Bye! Come back again soon."
            ]
          },
          {
            "tag": "thanks",
            "patterns": ["Thanks", "Thank you", "That's helpful", "Thank's a lot!"],
            "responses": ["Happy to help!", "Any time!", "My pleasure"]
          },
          {
            "tag": "items",
            "patterns": [
              "Which items do you have?",
              "What kinds of items are there?",
              "What do you sell?"
            ],
            "responses": [
              "We sell coffee and tea",
              "We have coffee and tea"
            ]
          },
          {
            "tag": "payments",
            "patterns": [
              "Do you take credit cards?",
              "Do you accept Mastercard?",
              "Can I pay with Paypal?",
              "Are you cash only?"
            ],
            "responses": [
              "We accept VISA, Mastercard and Paypal",
              "We accept most major credit cards, and Paypal"
            ]
          },
          {
            "tag": "delivery",
            "patterns": [
              "How long does delivery take?",
              "How long does shipping take?",
              "When do I get my delivery?"
            ],
            "responses": [
              "Delivery takes 2-4 days",
              "Shipping takes 2-4 days"
            ]
          },
          {
            "tag": "funny",
            "patterns": [
              "Tell me a joke!",
              "Tell me something funny!",
              "Do you know a joke?"
            ],
            "responses": [
              "Why did the hipster burn his mouth? He drank the coffee before it was cool.",
              "What did the buffalo say when his son left for college? Bison."
            ]
          }
        ]
      }
      """
  def get(self) -> dict:
    return json.loads(self.data)

class Nltk_utils:
  def __init__(self, download_punkt:bool=False)->None:
    if download_punkt:
      nltk.download('punkt')
    self.stemmer = PorterStemmer()

  def tokenize(self, sentence:str) -> list:
    return nltk.word_tokenize(sentence)

  def stem(self, word:str) -> str:
    return self.stemmer.stem(word.lower())

  def bag_of_words(self, tokenized_sentence:list, all_words:list) -> np.float32:
    """
    sentence = ['hello', 'how'  , 'are', 'you']
    words =    ['hi'   , 'hello', 'I'  , 'you', 'bye', 'thank', 'cool']
    bag =      [ 0     ,  1     ,  0   ,  1   ,  0   ,  0     ,  0]
    """

    tokenized_sentence = [self.stem(word) for word in tokenized_sentence]
    bag = np.zeros(len(all_words), dtype=np.float32)

    for idx, word in enumerate(all_words):
      if word in tokenized_sentence:
        bag[idx] = 1.0

    return bag

"""
nltk_utils = Nltk_utils()

a = "how long does shipping take?"
print(a)
a = nltk_utils.tokenize(a)
print(a)

words = ["organize", "organizes", "organizing"]

stemmed_words =[nltk_utils.stem(word) for word in words]

print(stemmed_words)
"""

"""
n = Nltk_utils()
sentence = ['hello', 'how'  , 'are', 'you']
words =    ['hi'   , 'hello', 'I'  , 'you', 'bye', 'thank', 'cool']
bag = n.bag_of_words(sentence, words)
print(bag)
"""

class Nlp_preprocessing(object):
  def __init__(self) -> None:
    self.intents = Internal_dataset().get()
    self.all_words = []
    self.tags = []
    self.xy = []
    self.ignore_words = ['?','!', '.', ',']
    self.nltk_utils = Nltk_utils()

    self.X_train = []
    self.y_train = []

  def preprocess(self) -> None:
    for intent in self.intents['intents']:
      tag = intent['tag']
      self.tags.append(tag)

      for pattern in intent['patterns']:
        w = self.nltk_utils.tokenize(pattern)
        self.all_words.extend(w)
        self.xy.append((w,tag))

    self.all_words = [self.nltk_utils.stem(word) for word in self.all_words if word not in self.ignore_words]

    self.all_words = sorted(set(self.all_words))
    self.tags = sorted(set(self.tags))

    #print(self.all_words)
    #print(self.tags)

    for (pattern_sentence, tag) in self.xy:
      bag = self.nltk_utils.bag_of_words(pattern_sentence, self.all_words)
      self.X_train.append(bag)
      label = self.tags.index(tag)

      self.y_train.append(label)

    self.X_train = np.array(self.X_train)
    self.y_train = np.array(self.y_train)





t = Nlp_preprocessing().preprocess()

class ChatDataset(Dataset):
  def __init__(self, n_samples, x_data, y_data) -> None:
    self.n_samples:int = n_samples #len(self.nlpp.X_train)
    self.x_data = x_data #self.nlpp.X_train
    self.y_data = y_data #self.nlpp.y_train

    #dataset [idx]

  def __getitem__(self, idx:int) -> list:
    return self.x_data[idx], self.y_data[idx]

  def __len__(self) -> int:
    return self.n_samples


# creating model


class NerualNet(nn.Module):
  def __init__(self, input_size, hidden_size, num_classes) -> None:
    super(NerualNet, self).__init__()
    self.li1 = nn.Linear(input_size, hidden_size)
    self.li2 = nn.Linear(hidden_size, hidden_size)
    self.li3 = nn.Linear(hidden_size, num_classes)

    self.relu = nn.ReLU()

  def forward(self, x):
    out = self.li1(x)
    out = self.relu(out)
    out = self.li2(out)
    out = self.relu(out)
    out = self.li3(out)

    return out

nlpp = Nlp_preprocessing()
nlpp.preprocess() # first we need preprocessing

#HyperParameters

batch_size = 8

hidden_size = 8
output_size = len(nlpp.tags)
input_size = len(nlpp.X_train[0])

learning_rate = 0.001

num_epochs = 1000


print(input_size, len(nlpp.all_words))
print(output_size, nlpp.tags)
dataset = ChatDataset(len(nlpp.X_train), nlpp.X_train, nlpp.y_train)

train_loader = DataLoader(dataset=dataset, batch_size = batch_size, shuffle=True) # , num_workers = 2)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = NerualNet(input_size, hidden_size, output_size)

# loss and optimizer

ciriterion = nn.CrossEntropyLoss()

optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)

# train loop

for epoch in range(num_epochs):

  for (words, labels) in train_loader:
    words = words.to(device)
    labels = labels.to(device)

    #foward
    outputs = model(words)
    loss = ciriterion(outputs, labels)

    #backward and optimizer
    optimizer.zero_grad()

    loss.backward()
    optimizer.step()

  if (epoch +1) %50 == 0:
    print(f"epcoh {epoch+1}/{num_epochs}, loss = {loss.item():.4f}")
print(f'final loss, loss = {loss.item():.4f}')

data = {
    "model_state":model.state_dict(),
    "input_size": input_size,
    "output_size": output_size,
    "hidden_size": hidden_size,
    "all_words": nlpp.all_words,
    "tags": nlpp.tags
}
FILE = "data.pth"

torch.save(data, FILE)

print(f'Model saved into -> {FILE}')

class CHAT:
  def __init__(self) -> None:
    pass

  def chat(self):
    n = Nltk_utils()
    bot_name = "testbot1"
    print("chat started.")
    while True:
      sentence = input("say something: ")
      if sentence == "quit":
        break
      sentence = n.tokenize(sentence)
      X = n.bag_of_words(sentence,nlpp.all_words)
      X = X.reshape(1, X.shape[0])
      X = torch.from_numpy(X)

      output = model(X)
      _, predicted = torch.max(output, dim=1)

      tag =  nlpp.tags[predicted.item()]

      probs = torch.softmax(output, dim=1)
      prob = probs[0][predicted.item()]

      if prob.item() > 0.75:
        for intent in nlpp.intents['intents']:
          if tag == intent['tag']:
            print(f'{bot_name}: {random.choice(intent["responses"])}')

      else:
        print(f'{bot_name}: I dont understand...')



  def save(self, data, FILE):
    torch.save(data, FILE)
    print(f'Model saved into -> {FILE}')

  def load(self):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    intents = nlpp.intents
    FILE = 'data.pth'
    data = torch.load(FILE)

    input_size = data['input_size']
    hidden_size = data['hidden_size']
    output_size = data['output_size']
    all_words = data['all_words']
    tags = data['tags']

    model_state = data['model_state']

    model = NerualNet(input_size, hidden_size, output_size).to(device)
    model.load_state_dict(model_state)
    model.eval()
    print(f"Model loaded from this file ->{FILE}")


chat = CHAT()

data = {
  "model_state":model.state_dict(),
  "input_size": input_size,
  "output_size": output_size,
  "hidden_size": hidden_size,
  "all_words": nlpp.all_words,
  "tags": nlpp.tags
}

FILE = "data.pth"

chat.save(data, FILE)

chat.load()

chat.chat()
